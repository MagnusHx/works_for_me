[project]
name = "audio_emotion"
version = "0.0.1"
description = "Audio emotion recognition using deep learning"
readme = "README.md"
requires-python = ">=3.11,<3.12"

# Base deps: things you truly need in *all* installs
dependencies = [
  "numpy<2",
  "hydra-core>=1.3.2",
  "loguru>=0.7.3",
  "typer==0.15.1",
]

[project.optional-dependencies]
# Run the FastAPI service
api = [
  "fastapi==0.115.6",
  "uvicorn==0.34.0",
]

# Typical training/data/audio stack (no torch here on purpose)
train = [
  "kaggle>=1.8.3",
  "kagglehub>=0.4.0",
  "librosa>=0.11.0",
  "soundfile>=0.13.1",
  "matplotlib>=3.10.8",
]

# Choose ONE accelerator extra:
cpu = [
  "torch==2.0.1",
  "torchaudio==2.0.2",
]

cu117 = [
  "torch==2.0.1+cu117",
  "torchaudio==2.0.2+cu117",
]

[tool.uv]
# Prevent installing both cpu and cu117 at the same time
conflicts = [
  [
    { extra = "cpu" },
    { extra = "cu117" },
  ],
]

[tool.uv.sources]
# Only pin to the CUDA index when the user explicitly selects --extra cu117
torch = [{ index = "pytorch-cu117", extra = "cu117" }]
torchaudio = [{ index = "pytorch-cu117", extra = "cu117" }]

[[tool.uv.index]]
name = "pytorch-cu117"
url = "https://download.pytorch.org/whl/cu117"
explicit = true
