[build-system]
requires = ["uv_build>=0.9.22,<0.10.0"]
build-backend = "uv_build"

[project]
name = "audio_emotion"
version = "0.0.1"
description = "Audio emotion recognition using deep learning"
readme = "README.md"
requires-python = ">=3.11,<3.12"

dependencies = [
  "numpy<2",
  "hydra-core>=1.3.2",
  "loguru>=0.7.3",
  "typer==0.15.1",
  "dvc-gs>=3.0.2",
  "pre-commit>=4.5.1",
  "wandb>=0.24.0",
  "bentoml>=1.4.33",
]

[project.optional-dependencies]
api = [
  "fastapi==0.115.6",
  "uvicorn==0.34.0",
]
dev = [
  "black>=24.0.0",
  "mypy>=1.9.0",
]

[dependency-groups]

train = [
  "kaggle>=1.8.3",
  "kagglehub>=0.4.0",
  "librosa>=0.11.0",
  "soundfile>=0.13.1",
  "matplotlib>=3.10.8",
  "coverage>=7.13.1",
  "pytest>=9.0.2",
  "ruff>=0.4.0",

  # macOS (CPU)
  "torch==2.0.1; sys_platform == 'darwin'",
  "torchaudio==2.0.2; sys_platform == 'darwin'",

  # Linux x86_64 (CUDA cu117 wheels exist here)
  "torch==2.10.0; sys_platform == 'linux' and platform_machine == 'x86_64'",
  "torchaudio==2.0.2+cu117; sys_platform == 'linux' and platform_machine == 'x86_64'",

  # Linux ARM64 (no cu117 wheels -> use CPU wheels from PyPI)
  "torch==2.0.1; sys_platform == 'linux' and platform_machine == 'aarch64'",
  "torchaudio==2.0.2; sys_platform == 'linux' and platform_machine == 'aarch64'",

  # Windows (CUDA cu117 wheels exist for amd64)
  "torch==2.0.1+cu117; sys_platform == 'win32' and (platform_machine == 'AMD64' or platform_machine == 'x86_64')",
  "torchaudio==2.0.2+cu117; sys_platform == 'win32' and (platform_machine == 'AMD64' or platform_machine == 'x86_64')",
]

[tool.uv.sources]
torch = [
  { index = "pytorch-cu117", marker = "(sys_platform == 'linux' and platform_machine == 'x86_64') or (sys_platform == 'win32' and (platform_machine == 'AMD64' or platform_machine == 'x86_64'))" },
]
torchaudio = [
  { index = "pytorch-cu117", marker = "(sys_platform == 'linux' and platform_machine == 'x86_64') or (sys_platform == 'win32' and (platform_machine == 'AMD64' or platform_machine == 'x86_64'))" },
]

[[tool.uv.index]]
name = "pytorch-cu117"
url = "https://download.pytorch.org/whl/cu117"
explicit = true

[project.scripts]
audio-emotion = "audio_emotion.cli:app"
audio-emotion-train = "audio_emotion.train:app"

[tool.coverage.run]
branch = true
source = ["src/audio_emotion"]

[tool.coverage.report]
show_missing = true
skip_covered = false
exclude_lines = [
  "if __name__ == \"__main__\":",
  "pragma: no cover",
]
