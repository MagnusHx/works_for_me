{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49803ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import librosa \n",
    "import numpy as np\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e484289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ace8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio_librosa(\n",
    "    wav_path: str,\n",
    "    target_sr: int = 16000,\n",
    "    clip_seconds: float = 4.0,\n",
    "    n_fft: int = 512,\n",
    "    hop_length: int = 160,\n",
    "    win_length: int | None = 400,\n",
    "    center: bool = True,\n",
    "    eps: float = 1e-8,\n",
    " ):\n",
    "    \"\"\"\n",
    "    Returns a log-magnitude STFT \"image\" suitable for 2D CNNs.\n",
    "    Output shape: (1, F, T) where F = n_fft//2 + 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load only the first `clip_seconds` worth of audio (or less if file is shorter)\n",
    "    y, sr = librosa.load(\n",
    "        wav_path,\n",
    "        sr=target_sr,\n",
    "        mono=True,\n",
    "        offset=0.0,\n",
    "        duration=clip_seconds,\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # Ensure fixed length by padding if needed (librosa will NOT pad automatically)\n",
    "    target_len = int(sr * clip_seconds)\n",
    "    if y.shape[0] < target_len:\n",
    "        y = np.pad(y, (0, target_len - y.shape[0]), mode=\"constant\")\n",
    "    elif y.shape[0] > target_len:\n",
    "        # Usually won't happen because duration=clip_seconds, but kept for safety\n",
    "        y = y[:target_len]\n",
    "\n",
    "    # STFT -> magnitude spectrogram\n",
    "    S = librosa.stft(\n",
    "        y,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=win_length,\n",
    "        window=\"hann\",\n",
    "        center=center,\n",
    "    )\n",
    "\n",
    "    mag = np.abs(S)\n",
    "    log_mag = np.log(mag + eps)\n",
    "\n",
    "    # Per-sample normalization\n",
    "    log_mag = (log_mag - log_mag.mean()) / (log_mag.std() + 1e-6)\n",
    "\n",
    "    return log_mag[np.newaxis, :, :].astype(np.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
